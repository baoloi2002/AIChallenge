{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MP4 to MP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "\n",
    "def get_audio_from_video(video_path, audio_path):\n",
    "    video = VideoFileClip(video_path)\n",
    "    audio = video.audio\n",
    "    audio.write_audiofile(audio_path)\n",
    "    video.close()\n",
    "    audio.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def scan_file_path_in_folder(directory):\n",
    "    lst = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # check files in the directory\n",
    "        for file in files:\n",
    "            lst.append(os.path.join(root, file))\n",
    "    return lst\n",
    "\n",
    "\n",
    "def scan_file_name_in_folder(directory):\n",
    "    lst = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # check files in the directory\n",
    "        for file in files:\n",
    "            # remove the extension\n",
    "            file_name = os.path.splitext(file)[0]\n",
    "            lst.append(file_name)\n",
    "    return lst\n",
    "\n",
    "\n",
    "video_a = \"Video_a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in Audio\\L09_V003.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "input_path = scan_file_path_in_folder(video_a)\n",
    "output_path = scan_file_name_in_folder(video_a)\n",
    "\n",
    "for i in range(len(input_path)):\n",
    "    # check if mp3 file already exists then skip\n",
    "    if os.path.exists(\"Audio\\\\\" + output_path[i] + \".mp3\"):\n",
    "        continue\n",
    "    get_audio_from_video(input_path[i], \"Audio\\\\\" + output_path[i] + \".mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/363 [00:00<?, ?it/s]Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      " 71%|███████   | 257/363 [07:02<18:26, 10.43s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "100%|██████████| 363/363 [1:21:01<00:00, 13.39s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "# Initialize the pipeline and specify the device\n",
    "transcriber = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"vinai/PhoWhisper-tiny\",\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    ")\n",
    "\n",
    "input_path = scan_file_path_in_folder(\"Audio\")\n",
    "output_path = scan_file_name_in_folder(video_a)\n",
    "\n",
    "for i in tqdm(range(len(input_path))):\n",
    "    # check if txt file already exists then skip\n",
    "    if os.path.exists(\"Audio_text\\\\\" + output_path[i] + \".txt\"):\n",
    "        continue\n",
    "    # no grad\n",
    "    with torch.no_grad():\n",
    "        out = transcriber(input_path[i])['text']\n",
    "    with open(\"Audio_text\\\\\" + output_path[i] + \".txt\", \"w\", encoding=\"utf-8\" ) as f:\n",
    "        f.write(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AiChallenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
