{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fixed_Length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AIChallenge\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1602: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "d:\\AIChallenge\\venv\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# BARTpho-syllable\n",
    "# syllable_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bartpho-syllable\")\n",
    "# bartpho_syllable = AutoModel.from_pretrained(\"vinai/bartpho-syllable\")\n",
    "# TXT = \"Chúng tôi là những nghiên cứu viên.\"\n",
    "# input_ids = syllable_tokenizer(TXT, return_tensors=\"pt\")[\"input_ids\"]\n",
    "# features = bartpho_syllable(input_ids)\n",
    "\n",
    "# BARTpho-word\n",
    "word_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bartpho-word-base\")\n",
    "bartpho_word = AutoModel.from_pretrained(\"vinai/bartpho-word-base\")\n",
    "# to cuda\n",
    "bartpho_word.to(\"cuda\")\n",
    "bartpho_word.eval()\n",
    "for param in bartpho_word.parameters():\n",
    "    param.requires_grad = False\n",
    "# TXT = \"Chúng_tôi là những nghiên_cứu_viên .\"\n",
    "# input_ids = word_tokenizer(TXT, return_tensors=\"pt\")[\"input_ids\"]\n",
    "# features = bartpho_word(input_ids.to(\"cuda\"))\n",
    "\n",
    "# input_ids = word_tokenizer.encode(TXT, return_tensors=\"pt\").to(\"cuda\")\n",
    "# print(input_ids)\n",
    "# # check if input_ids is in cuda\n",
    "# features = bartpho_word(input_ids).last_hidden_state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chúng_tôi là những nghiên_cứu_viên . \n"
     ]
    }
   ],
   "source": [
    "# Word segmentation\n",
    "import py_vncorenlp\n",
    "\n",
    "# py_vncorenlp.download_model(save_dir=r\"D:\\VQA\\Notebook\\VnCoreNLP\")\n",
    "\n",
    "# Load the word and sentence segmentation component\n",
    "rdrsegmenter = py_vncorenlp.VnCoreNLP(\n",
    "    annotators=[\"wseg\"],\n",
    "    save_dir=r\"D:\\AIChallenge\\VnCoreNLP\",\n",
    ")\n",
    "\n",
    "# change dir to C:\\Users\\Asus.LAPTOP-8EU9PHJL.000\\Desktop\\VQA\\Notebook\n",
    "import os\n",
    "\n",
    "os.chdir(r\"D:\\AIChallenge\")\n",
    "\n",
    "\n",
    "def Word_Segmentation(text):\n",
    "    output = rdrsegmenter.word_segment(text)\n",
    "    if len(output) > 0:\n",
    "        # join all words in the list\n",
    "        res = \"\"\n",
    "        for i in output:\n",
    "            res += i + \" \"\n",
    "        return res\n",
    "    else:\n",
    "        output = \"\"\n",
    "    return output\n",
    "\n",
    "\n",
    "print(Word_Segmentation(\"Chúng tôi là những nghiên cứu viên.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def scan_file_path_in_folder(directory):\n",
    "    lst = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # check files in the directory\n",
    "        for file in files:\n",
    "            lst.append(os.path.join(root, file))\n",
    "    return lst\n",
    "\n",
    "\n",
    "def scan_file_name_in_folder(directory):\n",
    "    lst = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # check files in the directory\n",
    "        for file in files:\n",
    "            # remove the extension\n",
    "            file_name = os.path.splitext(file)[0]\n",
    "            lst.append(file_name)\n",
    "    return lst\n",
    "\n",
    "\n",
    "audio_text = r\"Data\\rawData\\Audio_text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_lst = scan_file_path_in_folder(\"Data\\\\PreporcessData\\\\Audio_key_text\\\\L01_V001\")\n",
    "# name_lst = scan_file_name_in_folder(audio_text)\n",
    "# print(path_lst)\n",
    "# print(name_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst = scan_file_path_in_folder(audio_text)\n",
    "name_lst = scan_file_name_in_folder(audio_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"Data\\\\PreporcessData\\\\keyframes_ImageCaption\"\n",
    "# path_lst = scan_file_path_in_folder(path)\n",
    "# name_lst = scan_file_name_in_folder(path)\n",
    "# print(path_lst)\n",
    "# print(name_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path, name in tqdm(zip(path_lst, name_lst)):\n",
    "#     out = f\"Data\\PreporcessData\\keyframes_ImageCaption_bartpho\\{name}.pt\"\n",
    "#     # check if the file is already processed\n",
    "#     if os.path.exists(out):\n",
    "#         continue\n",
    "#     # read text\n",
    "#     with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "#         text = f.read()\n",
    "#     # join text\n",
    "#     text = Word_Segmentation(text)\n",
    "#     # remove every '.', ',', '!', '?'\n",
    "#     text = text.replace(\".\", \" \").replace(\",\", \" \").replace(\"!\", \" \").replace(\"?\", \" \")\n",
    "#     # clean ' 'ArithmeticError\n",
    "#     text = \" \".join(text.split())\n",
    "#     text = text.split(\" \")\n",
    "#     num_chunks = (len(text) + Fixed_Length - 1) // Fixed_Length\n",
    "#     max_len_each_chunk = (len(text) + num_chunks - 1) // num_chunks\n",
    "#     lst_text = []\n",
    "#     for i in range(0, len(text), max_len_each_chunk):\n",
    "#         lst_text.append([\" \".join(text[i : i + max_len_each_chunk])])\n",
    "#     lst_ids = [\n",
    "#         word_tokenizer.encode(\n",
    "#             i[0],\n",
    "#             return_tensors=\"pt\",\n",
    "#             padding=\"max_length\",\n",
    "#             max_length=max_len_each_chunk,\n",
    "#             truncation=True,\n",
    "#             add_special_tokens=False,\n",
    "#         ).to(\"cuda\")\n",
    "#         for i in lst_text\n",
    "#     ]\n",
    "#     with torch.no_grad():\n",
    "#         # check if input_ids is in cuda\n",
    "#         lst_outputs = [bartpho_word(i) for i in lst_ids]\n",
    "#         lst_features = [i.last_hidden_state[0] for i in lst_outputs]\n",
    "#         # stack all features to a tensor\n",
    "#         features = torch.stack(lst_features)\n",
    "#     # save features\n",
    "#     torch.save(features, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name in tqdm(name_lst):\n",
    "#     path_lst = scan_file_path_in_folder(f\"Data\\\\PreporcessData\\\\Audio_key_text\\\\{name}\")\n",
    "#     sub_name_lst = scan_file_name_in_folder(\n",
    "#         f\"Data\\\\PreporcessData\\\\Audio_key_text\\\\{name}\"\n",
    "#     )\n",
    "#     for path, sub_name in zip(path_lst, sub_name_lst):\n",
    "#         out_path = f\"Data\\\\PreporcessData\\\\Audio_key_text_bartpho\\\\{name}_{sub_name}.pt\"\n",
    "#         # check if the file is already exist\n",
    "#         if os.path.exists(out_path):\n",
    "#             continue\n",
    "#         # read text\n",
    "#         with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "#             text = f.read()\n",
    "#         # join text\n",
    "#         text = Word_Segmentation(text)\n",
    "#         # remove every '.', ',', '!', '?'\n",
    "#         text = (\n",
    "#             text.replace(\".\", \" \").replace(\",\", \" \").replace(\"!\", \" \").replace(\"?\", \" \")\n",
    "#         )\n",
    "#         # clean ' 'ArithmeticError\n",
    "#         text = \" \".join(text.split())\n",
    "#         # split the text into multiple parts with at most 40 words\n",
    "#         text = text.split(\" \")\n",
    "#         num_chunks = (len(text) + Fixed_Length - 1) // Fixed_Length\n",
    "#         max_len_each_chunk = (len(text) + num_chunks - 1) // num_chunks\n",
    "#         # if (len(text) < 5):\n",
    "#         #     continue\n",
    "#         lst_text = []\n",
    "#         for i in range(0, len(text), max_len_each_chunk):\n",
    "#             lst_text.append([\" \".join(text[i : i + max_len_each_chunk])])\n",
    "#         lst_ids = [\n",
    "#             word_tokenizer.encode(\n",
    "#                 i[0],\n",
    "#                 return_tensors=\"pt\",\n",
    "#                 padding=\"max_length\",\n",
    "#                 max_length=max_len_each_chunk,\n",
    "#                 truncation=True,\n",
    "#                 add_special_tokens=False,\n",
    "#             ).to(\"cuda\")\n",
    "#             for i in lst_text\n",
    "#         ]\n",
    "#         with torch.no_grad():\n",
    "#             # check if input_ids is in cuda\n",
    "#             lst_outputs = [bartpho_word(i) for i in lst_ids]\n",
    "#             lst_features = [i.last_hidden_state[0] for i in lst_outputs]\n",
    "#             # stack all features to a tensor\n",
    "#             features = torch.stack(lst_features)\n",
    "#         # save features\n",
    "#         torch.save(features, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "726it [01:41,  7.17it/s]\n"
     ]
    }
   ],
   "source": [
    "for path, name in tqdm(zip(path_lst, name_lst)):\n",
    "    # read text\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    # join text\n",
    "    text = Word_Segmentation(\"tôi \" + text)\n",
    "    # remove every '.', ',', '!', '?'\n",
    "    text = text.replace(\".\", \" \").replace(\",\", \" \").replace(\"!\", \" \").replace(\"?\", \" \")\n",
    "    # clean ' 'ArithmeticError\n",
    "    text = \" \".join(text.split())\n",
    "    # write text\n",
    "    with open(\n",
    "        f\"Data\\PreporcessData\\Audio_text_wseg\\{name}.txt\", \"w\", encoding=\"utf-8\"\n",
    "    ) as f:\n",
    "        # write to each line\n",
    "        f.write(text)\n",
    "    # split the text into multiple parts with at most 40 words\n",
    "    text = text.split(\" \")\n",
    "    num_chunks = (len(text) + Fixed_Length - 1) // Fixed_Length\n",
    "    max_len_each_chunk = (len(text) + num_chunks - 1) // num_chunks\n",
    "    lst_text = []\n",
    "    for i in range(0, len(text), max_len_each_chunk):\n",
    "        lst_text.append([\" \".join(text[i : i + max_len_each_chunk])])\n",
    "    lst_ids = [\n",
    "        word_tokenizer.encode(\n",
    "            i[0],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_len_each_chunk,\n",
    "            truncation=True,\n",
    "            add_special_tokens=False,\n",
    "        ).to(\"cuda\")\n",
    "        for i in lst_text\n",
    "    ]\n",
    "    with torch.no_grad():\n",
    "        # check if input_ids is in cuda\n",
    "        lst_outputs = [bartpho_word(i) for i in lst_ids]\n",
    "        lst_features = [i.last_hidden_state[0] for i in lst_outputs]\n",
    "        # stack all features to a tensor\n",
    "        features = torch.stack(lst_features)\n",
    "    # save features\n",
    "    torch.save(features, f\"Data\\PreporcessData\\Audio_text_bartpho\\{name}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
