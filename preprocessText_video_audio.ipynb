{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AIChallenge\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# BARTpho-syllable\n",
    "# syllable_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bartpho-syllable\")\n",
    "# bartpho_syllable = AutoModel.from_pretrained(\"vinai/bartpho-syllable\")\n",
    "# TXT = \"Chúng tôi là những nghiên cứu viên.\"\n",
    "# input_ids = syllable_tokenizer(TXT, return_tensors=\"pt\")[\"input_ids\"]\n",
    "# features = bartpho_syllable(input_ids)\n",
    "\n",
    "# BARTpho-word\n",
    "word_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bartpho-word-base\")\n",
    "bartpho_word = AutoModel.from_pretrained(\"vinai/bartpho-word-base\")\n",
    "# to cuda\n",
    "bartpho_word.to(\"cuda\")\n",
    "bartpho_word.eval()\n",
    "for param in bartpho_word.parameters():\n",
    "    param.requires_grad = False\n",
    "# TXT = \"Chúng_tôi là những nghiên_cứu_viên .\"\n",
    "# input_ids = word_tokenizer(TXT, return_tensors=\"pt\")[\"input_ids\"]\n",
    "# features = bartpho_word(input_ids.to(\"cuda\"))\n",
    "\n",
    "# input_ids = word_tokenizer.encode(TXT, return_tensors=\"pt\").to(\"cuda\")\n",
    "# print(input_ids)\n",
    "# # check if input_ids is in cuda\n",
    "# features = bartpho_word(input_ids).last_hidden_state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chúng_tôi là những nghiên_cứu_viên . \n"
     ]
    }
   ],
   "source": [
    "# Word segmentation\n",
    "import py_vncorenlp\n",
    "\n",
    "# py_vncorenlp.download_model(save_dir=r\"D:\\VQA\\Notebook\\VnCoreNLP\")\n",
    "\n",
    "# Load the word and sentence segmentation component\n",
    "rdrsegmenter = py_vncorenlp.VnCoreNLP(\n",
    "    annotators=[\"wseg\"],\n",
    "    save_dir=r\"D:\\AIChallenge\\VnCoreNLP\",\n",
    ")\n",
    "\n",
    "# change dir to C:\\Users\\Asus.LAPTOP-8EU9PHJL.000\\Desktop\\VQA\\Notebook\n",
    "import os\n",
    "\n",
    "os.chdir(r\"D:\\AIChallenge\")\n",
    "\n",
    "\n",
    "def Word_Segmentation(text):\n",
    "    output = rdrsegmenter.word_segment(text)\n",
    "    if len(output) > 0:\n",
    "        # join all words in the list\n",
    "        res = \"\"\n",
    "        for i in output:\n",
    "            res += i + \" \"\n",
    "        return res\n",
    "    else:\n",
    "        output = \"\"\n",
    "    return output\n",
    "\n",
    "\n",
    "print(Word_Segmentation(\"Chúng tôi là những nghiên cứu viên.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def scan_file_path_in_folder(directory):\n",
    "    lst = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # check files in the directory\n",
    "        for file in files:\n",
    "            lst.append(os.path.join(root, file))\n",
    "    return lst\n",
    "\n",
    "\n",
    "def scan_file_name_in_folder(directory):\n",
    "    lst = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # check files in the directory\n",
    "        for file in files:\n",
    "            # remove the extension\n",
    "            file_name = os.path.splitext(file)[0]\n",
    "            lst.append(file_name)\n",
    "    return lst\n",
    "\n",
    "\n",
    "audio_text = r\"Data\\rawData\\Audio_text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst = scan_file_path_in_folder(audio_text)\n",
    "name_lst = scan_file_name_in_folder(audio_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "363it [01:47,  3.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for path, name in tqdm(zip(path_lst, name_lst)):\n",
    "    # read text\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    # join text\n",
    "    text = Word_Segmentation(text)\n",
    "    # remove every '.', ',', '!', '?'\n",
    "    text = text.replace(\".\", \" \").replace(\",\", \" \").replace(\"!\", \" \").replace(\"?\", \" \")\n",
    "    # clean ' 'ArithmeticError\n",
    "    text = \" \".join(text.split())\n",
    "    # write text\n",
    "    with open(\n",
    "        f\"Data\\PreporcessData\\Audio_text_wseg\\{name}.txt\", \"w\", encoding=\"utf-8\"\n",
    "    ) as f:\n",
    "        # write to each line\n",
    "        f.write(text)\n",
    "    # split the text into multiple parts with at most 100 words\n",
    "    text = text.split(\" \")\n",
    "    lst_text = []\n",
    "    for i in range(0, len(text), 100):\n",
    "        lst_text.append([\" \".join(text[i : i + 100])])\n",
    "    lst_ids = [\n",
    "        word_tokenizer.encode(\n",
    "            i[0],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "        ).to(\"cuda\")\n",
    "        for i in lst_text\n",
    "    ]\n",
    "    with torch.no_grad():\n",
    "        # check if input_ids is in cuda\n",
    "        lst_outputs = [bartpho_word(i) for i in lst_ids]\n",
    "        lst_features = [i.last_hidden_state[0] for i in lst_outputs]\n",
    "        # stack all features to a tensor\n",
    "        features = torch.stack(lst_features)\n",
    "    # save features\n",
    "    torch.save(features, f\"Data\\PreporcessData\\Audio_text_bartpho\\{name}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
